{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0597c21",
   "metadata": {},
   "source": [
    "# é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰\n",
    "\n",
    "é€»è¾‘å›å½’æ˜¯ä¸€ç§ç”¨äºäºŒåˆ†ç±»é—®é¢˜çš„ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼Œå¸¸ç”¨äºé¢„æµ‹äº‹ä»¶çš„å‘ç”Ÿæ¦‚ç‡ï¼ˆä¾‹å¦‚æˆåŠŸ/å¤±è´¥ã€æ˜¯/å¦ï¼‰ã€‚\n",
    "\n",
    "### ä¸çº¿æ€§å›å½’çš„åŒºåˆ«\n",
    "çº¿æ€§å›å½’ï¼šæ‹Ÿåˆä¸€æ¡ç›´çº¿ä»¥é¢„æµ‹è¿ç»­å€¼ï¼Œå…³æ³¨å˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»ã€‚\n",
    "\n",
    "é€»è¾‘å›å½’ï¼šä½¿ç”¨éçº¿æ€§å‡½æ•°ï¼ˆå¦‚ Sigmoidï¼‰é¢„æµ‹äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ï¼Œè¾“å‡ºå€¼åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚\n",
    "\n",
    "### ä½¿ç”¨ Sigmoid å‡½æ•°\n",
    "é€»è¾‘å›å½’çš„æ ¸å¿ƒæ˜¯ Sigmoid å‡½æ•°ï¼Œå®ƒå°†ä»»æ„å®æ•°æ˜ å°„åˆ° (0, 1) åŒºé—´ï¼š\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "$$\n",
    "z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n",
    "$$\n",
    "\n",
    "$ğ›½_0$ï¼šæˆªè·é¡¹ï¼ˆbiasï¼‰\n",
    "\n",
    "$ğ›½_ğ‘–$ï¼šç¬¬$ğ‘–$ä¸ªç‰¹å¾çš„æƒé‡ç³»æ•°\n",
    "\n",
    "$ğ‘¥_ğ‘–$ï¼šç¬¬$ğ‘–$ä¸ªè¾“å…¥ç‰¹å¾å€¼\n",
    "\n",
    "## Sigmoid è¾“å‡ºè§£é‡Š\n",
    "\n",
    "| ğ‘§ å€¼èŒƒå›´ | Sigmoid è¾“å‡º $$\\sigma(z)$$ | é¢„æµ‹å«ä¹‰                     |\n",
    "|-----------------|------------------------|--------------------------|\n",
    "| $$( z \\ll 0 )$$   | æ¥è¿‘ 0               | å¦å®šæ€§é¢„æµ‹ï¼ˆäº‹ä»¶ä¸å‘ç”Ÿï¼‰ |\n",
    "| $$( z \\gg 0 )$$  | æ¥è¿‘ 1               | è‚¯å®šæ€§é¢„æµ‹ï¼ˆäº‹ä»¶å‘ç”Ÿï¼‰   |\n",
    "| $$( z \\approx 0 )$$ | æ¥è¿‘ 0.5          | æ¨¡ç³Šè¾¹ç•Œï¼ˆä¸ç¡®å®šï¼‰       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e0e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¢„æµ‹æ¦‚ç‡: 0.9089\n",
      "é¢„æµ‹ç±»åˆ«: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid å‡½æ•°å®šä¹‰\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# çº¿æ€§ç»„åˆå‡½æ•°ï¼šz = Î²0 + Î²1*x1 + Î²2*x2 + ...\n",
    "def linear_combination(X, weights, bias):\n",
    "    return np.dot(X, weights) + bias\n",
    "\n",
    "# é¢„æµ‹å‡½æ•°ï¼šè¿”å›æ¦‚ç‡\n",
    "def predict_proba(X, weights, bias):\n",
    "    z = linear_combination(X, weights, bias)\n",
    "    return sigmoid(z)\n",
    "\n",
    "# äºŒåˆ†ç±»é¢„æµ‹ï¼šè¿”å› 0 æˆ– 1\n",
    "def predict(X, weights, bias, threshold=0.5):\n",
    "    proba = predict_proba(X, weights, bias)\n",
    "    return (proba >= threshold).astype(int)\n",
    "\n",
    "# ç¤ºä¾‹æ•°æ®\n",
    "X_sample = np.array([2.0, -1.0])        # ç‰¹å¾å€¼\n",
    "weights = np.array([0.8, -0.5])         # æƒé‡\n",
    "bias = 0.2                              # æˆªè·\n",
    "\n",
    "# æ‰§è¡Œé¢„æµ‹\n",
    "probability = predict_proba(X_sample, weights, bias)\n",
    "label = predict(X_sample, weights, bias)\n",
    "\n",
    "print(f\"é¢„æµ‹æ¦‚ç‡: {probability:.4f}\")\n",
    "print(f\"é¢„æµ‹ç±»åˆ«: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b244d",
   "metadata": {},
   "source": [
    "## æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ³•ï¼ˆMaximum Likelihood Estimationï¼‰\n",
    "\n",
    "åœ¨é€»è¾‘å›å½’ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä¸€ç»„å‚æ•°ï¼Œä½¿å¾—æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„é¢„æµ‹æ¦‚ç‡æœ€å¤§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ª**ä¼¼ç„¶å‡½æ•°**ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–ä½¿å…¶æœ€å¤§åŒ–ã€‚\n",
    "\n",
    "### æ•°å­¦è¡¨è¾¾\n",
    "\n",
    "å‡è®¾è®­ç»ƒæ•°æ®ä¸º $(x_i, y_i)$ï¼Œå…¶ä¸­ $ y_i \\in \\{0, 1\\} $ï¼Œåˆ™é€»è¾‘å›å½’çš„ä¼¼ç„¶å‡½æ•°ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "L(\\beta) = \\prod_{i=1}^{n} \\sigma(z_i)^{y_i} (1 - \\sigma(z_i))^{1 - y_i}\n",
    "$$\n",
    "\n",
    "æˆ‘ä»¬é€šå¸¸å¯¹æ•°åŒ–å¤„ç†ï¼Œå¾—åˆ°å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š\n",
    "\n",
    "$$\n",
    "\\log L(\\beta) = \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i)) \\right]\n",
    "$$\n",
    "\n",
    "ç„¶åä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ç­‰ä¼˜åŒ–ç®—æ³•ï¼Œæ±‚å‡ºä½¿å¯¹æ•°ä¼¼ç„¶å‡½æ•°æœ€å¤§åŒ–çš„å‚æ•°ğ›½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b92247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¼°è®¡çš„å‚æ•° Î²: [-13.50758443   4.9570286 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_likelihood(X, y, beta):\n",
    "    z = X @ beta\n",
    "    return np.sum(y * np.log(sigmoid(z)) + (1 - y) * np.log(1 - sigmoid(z)))\n",
    "\n",
    "def logistic_regression(X, y, lr=0.01, max_iter=10000, tol=1e-6):\n",
    "    m, n = X.shape\n",
    "    beta = np.zeros(n)\n",
    "    prev_ll = -np.inf\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        z = X @ beta\n",
    "        gradient = X.T @ (y - sigmoid(z))\n",
    "        beta += lr * gradient\n",
    "\n",
    "        ll = log_likelihood(X, y, beta)\n",
    "        if np.abs(ll - prev_ll) < tol:\n",
    "            break\n",
    "        prev_ll = ll\n",
    "\n",
    "    return beta\n",
    "\n",
    "# ç¤ºä¾‹æ•°æ®\n",
    "X = np.array([\n",
    "    [1, 0.5],\n",
    "    [1, 1.0],\n",
    "    [1, 1.5],\n",
    "    [1, 2.0],\n",
    "    [1, 2.5],\n",
    "    [1, 3.0],\n",
    "    [1, 3.5],\n",
    "    [1, 4.0],\n",
    "    [1, 4.5],\n",
    "    [1, 5.0]\n",
    "])  # ç¬¬ä¸€åˆ—æ˜¯åç½®é¡¹\n",
    "\n",
    "y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "beta_hat = logistic_regression(X, y)\n",
    "print(\"ä¼°è®¡çš„å‚æ•° Î²:\", beta_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec628835",
   "metadata": {},
   "source": [
    "### è¯´æ˜\n",
    "\n",
    "- ä½¿ç”¨çš„æ˜¯æ¢¯åº¦ä¸Šå‡æ³•ï¼ˆæœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶ï¼‰\n",
    "\n",
    "- X çš„ç¬¬ä¸€åˆ—æ˜¯å¸¸æ•°é¡¹ï¼ˆåç½®é¡¹ï¼‰\n",
    "\n",
    "- beta_hat æ˜¯ä¼°è®¡å¾—åˆ°çš„å‚æ•°å‘é‡ï¼Œå¯ç”¨äºé¢„æµ‹æ–°æ ·æœ¬çš„æ¦‚ç‡\n",
    "\n",
    "ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ scikit-learn å®ç°é€»è¾‘å›å½’çš„å®Œæ•´ Python ç¤ºä¾‹ï¼Œé€‚ç”¨äºäºŒåˆ†ç±»é—®é¢˜ï¼Œå¹¶åŒ…å«è®­ç»ƒã€é¢„æµ‹å’Œè¯„ä¼°æ­¥éª¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1daf0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†ç¡®ç‡ Accuracy: 0.6666666666666666\n",
      "æ··æ·†çŸ©é˜µ Confusion Matrix:\n",
      " [[1 0]\n",
      " [1 1]]\n",
      "åˆ†ç±»æŠ¥å‘Š Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.75      0.75      0.67         3\n",
      "weighted avg       0.83      0.67      0.67         3\n",
      "\n",
      "é¢„æµ‹æ¦‚ç‡ Predicted Probabilities:\n",
      " [[0.15205575 0.84794425]\n",
      " [0.92529562 0.07470438]\n",
      " [0.51048435 0.48951565]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ç¤ºä¾‹æ•°æ®ï¼šä½ å¯ä»¥æ›¿æ¢ä¸ºè‡ªå·±çš„ CSV æ–‡ä»¶\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],\n",
    "    'feature2': [1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    'target':   [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "})\n",
    "\n",
    "# ç‰¹å¾å’Œç›®æ ‡å˜é‡\n",
    "X = data[['feature1', 'feature2']]\n",
    "y = data['target']\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# åˆå§‹åŒ–å¹¶è®­ç»ƒæ¨¡å‹\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# é¢„æµ‹\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# è¯„ä¼°\n",
    "print(\"å‡†ç¡®ç‡ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"æ··æ·†çŸ©é˜µ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"åˆ†ç±»æŠ¥å‘Š Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# å¯é€‰ï¼šé¢„æµ‹æ¦‚ç‡\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print(\"é¢„æµ‹æ¦‚ç‡ Predicted Probabilities:\\n\", y_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129ea29",
   "metadata": {},
   "source": [
    "### è¯´æ˜\n",
    "\n",
    "- LogisticRegression() é»˜è®¤ä½¿ç”¨ L2 æ­£åˆ™åŒ–å’Œ lbfgs æ±‚è§£å™¨\n",
    "\n",
    "- predict() ç»™å‡ºç±»åˆ«é¢„æµ‹ï¼ˆ0 æˆ– 1ï¼‰\n",
    "\n",
    "- predict_proba() ç»™å‡ºå±äºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
    "\n",
    "- å¯é€šè¿‡ penalty, solver, C, max_iter ç­‰å‚æ•°è¿›è¡Œé«˜çº§é…ç½®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logistic-ViuxWiqp-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
